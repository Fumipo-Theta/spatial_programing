{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# §2-Extra カメラの投影変換\n",
    "\n",
    "この章では投影変換の実装方法を学びましょう。\n",
    "\n",
    "§2 で投影変換 (=ワールド座標系から画像座標系への変換) の大まかな流れを学びました。\n",
    "ここでは Open3D・numpy を使った投影変換の実装方法を確認しましょう。\n",
    "\n",
    "1. はじめに、ピンホールカメラでの投影変換の実装方法を確認しましょう。\n",
    "2. また、最後により複雑なカメラモデルである魚眼レンズカメラモデルにも触れてみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import sympy as sp\n",
    "from IPython.display import Math, display\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from util_lib.camera import (\n",
    "    OCamCalibOmniDirectionalCamera,\n",
    "    OCamCalibOmniDirectionalCameraParameters,\n",
    "    PinholeCameraParameters,\n",
    "    SimplePinholeCamera,\n",
    ")\n",
    "from util_lib.transformable_object import TransformableObject\n",
    "from util_lib.types import EulerOrder, ICamera, Transform\n",
    "from util_lib.visualization import draw_geometries\n",
    "\n",
    "# ベースとなるカメラ\n",
    "pinhole_camera_intrinsic = PinholeCameraParameters(focal_length=600,\n",
    "                                                   principal_point=(1200 / 2 - 0.5, 900 / 2 - 0.5),\n",
    "                                                   image_size=(1200, 900))\n",
    "initial_rotate = Rotation.from_euler(EulerOrder.xyz, [0, 0, 0], degrees=True).as_matrix()\n",
    "initial_pose = Transform.from_rotate_and_translate(initial_rotate, [0, 0, 0])\n",
    "view_camera = SimplePinholeCamera(pinhole_camera_intrinsic, initial_pose)\n",
    "\n",
    "\n",
    "# 行列表示用の関数\n",
    "def print_matrix(mat: np.ndarray | Transform) -> None:\n",
    "    if isinstance(mat, Transform):\n",
    "        mat_sym = sp.Matrix(mat.get_matrix())\n",
    "    else:\n",
    "        mat_sym = sp.Matrix(mat)\n",
    "    mat_sym = mat_sym.applyfunc(lambda x: sp.Symbol(f\"{x:.3f}\"))\n",
    "    display(Math(sp.latex(mat_sym)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワールド\n",
    "\n",
    "例として、下図のようなグリッド状の点群が設置されたワールドを考えてみましょう。\n",
    "\n",
    "点群の色は (赤, 緑, 青) の組で表され、ワールド座標の +x, +y, +z 方向にそれぞれ赤、緑、青の値が大きくなります。\n",
    "\n",
    "<img alt=\"World settings\" src=\"./notebook_assets/images/2_extra_world_settings.png\" style=\"width:600px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_cube_point_cloud(\n",
    "        num_points_per_axis: int = 50, cube_size: float=10, epsilon: float=0.0,\n",
    "    ) -> o3d.geometry.PointCloud:\n",
    "    \"\"\"Generate a grid cube with the specified number of points per axis and cube size.\"\"\"\n",
    "    line = np.linspace(0, num_points_per_axis, num_points_per_axis+1, dtype=np.float64)\n",
    "    scale = cube_size / num_points_per_axis\n",
    "\n",
    "    points = []\n",
    "    colors = []\n",
    "    rng = np.random.default_rng()\n",
    "    for x in line:\n",
    "        for y in line:\n",
    "            for z in line:\n",
    "                # 点が正確にグリッド上にあるとモアレが発生して見辛いので、座標値に適度な揺らぎを与える\n",
    "                points.append(\n",
    "                    [rng.normal(x, epsilon)*scale, rng.normal(y, epsilon)*scale, rng.normal(z, epsilon)*scale])\n",
    "                colors.append([x/num_points_per_axis, y/num_points_per_axis, z/num_points_per_axis])\n",
    "\n",
    "    # Open3D の点群オブジェクトの作り方\n",
    "    # 1. 空の PointCloud インスタンスを生成\n",
    "    # 2. 点の座標と色をそれぞれ、points 属性と colors 属性に設定する\n",
    "    #    - points と colors は点の数を N とすると、N x 3 の配列である\n",
    "    #    - points と colors は o3d.utility.Vector3dVector に変換したうえで設定する\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return pcd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カメラオブジェクト\n",
    "base_camera_obj = TransformableObject.load_model(\"data/camera.gltf\")\n",
    "\n",
    "# カメラ (初期姿勢をカメラオブジェクトに合わせる)\n",
    "pinhole_camera_intrinsic = PinholeCameraParameters(focal_length=600,\n",
    "                                                   principal_point=(1200 / 2 - 0.5, 900 / 2 - 0.5),\n",
    "                                                   image_size=(1200, 900))\n",
    "initial_rotate = Rotation.from_euler(EulerOrder.xyz, [-90, 180, 0], degrees=True).as_matrix()\n",
    "initial_pose = Transform.from_rotate_and_translate(initial_rotate, [0, 0, 0])\n",
    "base_camera = SimplePinholeCamera(pinhole_camera_intrinsic, initial_pose)\n",
    "\n",
    "# ワールド座標軸\n",
    "world_coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=1, origin=[0, 0, 0])\n",
    "\n",
    "# 画像座標軸 (後で使用)\n",
    "image_coordinate = o3d.geometry.TriangleMesh.create_coordinate_frame(size=500, origin=[0, 0, 0])\n",
    "\n",
    "# 立方体状の点群\n",
    "cube = generate_grid_cube_point_cloud(20, 5, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries(world_coordinate, cube, base_camera_obj, title=\"ワールドセッティング\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ピンホールカメラによる投影変換\n",
    "\n",
    "### カメラのセッティング\n",
    "\n",
    "最初に、カメラを点群の正面に移動しましょう。そして Open3D のカメラビューでの見え方を確認しましょう。\n",
    "\n",
    "下の左図はカメラと点群の位置関係を、右図はカメラに写る景色を示しています。\n",
    "\n",
    "<img alt=\"Camera settings\" src=\"./notebook_assets/images/2_extra_camera_in_front_of_cube.png\" style=\"width:600px;\" />\n",
    "\n",
    "<img alt=\"Open3D camera view\" src=\"./notebook_assets/images/2_extra_camera_view_in_front_of_cube.png\" style=\"width:600px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_center = np.mean(np.asarray(cube.points), axis=0)\n",
    "\n",
    "camera_obj = base_camera_obj.copy()\n",
    "# cube の中心を見るようにカメラを移動、またカメラを少し後ろに引く\n",
    "camera_obj.translate([cube_center[0], -3, cube_center[2]])\n",
    "\n",
    "camera = base_camera.copy()\n",
    "camera.transform(camera_obj.get_transform())\n",
    "\n",
    "draw_geometries(world_coordinate, cube, camera_obj, camera=camera, title=\"カメラセッティング\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ピンホールカメラモデルによる投影変換の実装方法\n",
    "\n",
    "§2 で学んだように、下記の手順で投影変換を行います。\n",
    "\n",
    "1. 事前準備として、変換対象の点のワールド座標のセットを得ます\n",
    "   * 点の数が $N$ であるとき、点の座標のセットを $3 \\times N$ の行列にまとめます\n",
    "   * Transformation のため、要素が全て `1` である行を追加し、$4 \\times N$ 行列にします\n",
    "   * また、ここでは点の座標を Open3D の PointCloud オブジェクトから抽出します\n",
    "2. 点のワールド座標にカメラ外部パラメータ行列をかけて、カメラ座標に変換します\n",
    "3. カメラ座標から正規画像座標に変換します\n",
    "   * カメラ座標の X, Y 座標を Z 座標で割り、カメラ正面の距離1単位にある仮想的なスクリーン上の座標にします\n",
    "4. 点の正規画像座標にカメラ行列をかけて、画像座標に変換します\n",
    "5. 追加でカメラに写っている点だけをフィルターします\n",
    "   1. ピンホールカメラではカメラの前方の点しか写らないので。カメラ座標への変換後にカメラ前方 (Z > 0) の点だけ残します\n",
    "   2. 画像座標への変換後、画像内部 (0 <= X <= 画像の幅 ・ 0 <= Y <= 画像の高さ) にある点だけ残します\n",
    "\n",
    "後の `projection_by_pinhole_camera()` 関数は上記の手順に従ってピンホールカメラモデルでの投影変換を実装したものです。この関数では、投影変換後の点の座標を使って新しい PointCloud オブジェクトを生成して返しています。\n",
    "\n",
    "\n",
    "下の左図は、点群が正規画像座標に変換された様子を示しています。図中の座標軸はカメラ座標系の座標軸です。\n",
    "点群が平面上になっていて、その中央が Z 軸の先端に接していることがわかります。\n",
    "\n",
    "下の右図は、点群が画像座標に変換された様子を示しています。図中の座標軸は画像座標系の座標軸で、奥方向が +Z すなわちカメラの視線方向を、+X が画像の右方向を、+Y が画像の下方向を向いています。\n",
    "点群が平面上になっていて、Open3D のカメラビューでの見え方と同じようになっていることがわかります。\n",
    "\n",
    "<img alt=\"Projected cube\" src=\"./notebook_assets/images/2_extra_cube_on_the_screen.png\" style=\"width:600px;\" />\n",
    "<img alt=\"Projected cube\" src=\"./notebook_assets/images/2_extra_projected_cube_from_front.png\" style=\"width:600px;\" />\n",
    "\n",
    "\n",
    "カメラモデルによらず、ワールド座標からカメラ座標への変換は外部パラメータ行列を用いて統一的に行うことができます。\n",
    "その一方で、カメラ座標から画像座標への変換は、カメラモデルに依存して定義が異なります。\n",
    "\n",
    "このチュートリアルで定義した `ICamera` インターフェースでは、ワールド座標から画像座標への一般化された変換を `world_to_camera()` メソッドで定義しています。\n",
    "\n",
    "後の `projection_by_camera()` 関数は、`ICamera` を実装したクラスの `world_to_camera()` メソッドを利用して投影変換を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_by_pinhole_camera(\n",
    "        pcd: o3d.geometry.PointCloud,\n",
    "        camera: SimplePinholeCamera,\n",
    "        *,\n",
    "        return_with_color: bool = True) -> tuple[o3d.geometry.PointCloud, o3d.geometry.PointCloud]:\n",
    "    \"\"\"\n",
    "    カメラの外部パラメータと内部パラメータを用いてステップバイステップで投影変換を行う.\n",
    "\n",
    "    Note:\n",
    "    ----\n",
    "    ピンホールカメラのように投影変換が行列の積で表現できることを前提とする\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def filter_visible_points(points: np.ndarray, image_width: int, image_height: int) -> np.ndarray:\n",
    "        # Filter points that are inside the image\n",
    "        mask = np.where(\n",
    "            (points[0, :] >= 0) & (points[0, :] <= image_width) & # 0 <= x <= image_width [pixel]\n",
    "            (points[1, :] >= 0) & (points[1, :] <= image_height)) # 0 <= y <= image_height [pixel]\n",
    "        return points[:, *mask], mask\n",
    "\n",
    "    extrinsic_matrix = camera.get_extrinsic_matrix()\n",
    "    camera_matrix = camera.get_intrinsic_matrix()\n",
    "    image_size = camera.get_image_size()\n",
    "\n",
    "    print(\"Extrinsic matrix (4x4)\")  # noqa: T201 説明用にあえて print を使用\n",
    "    print_matrix(extrinsic_matrix)\n",
    "    print(\"Camera matrix (3x3)\") # noqa: T201 説明用にあえて print を使用\n",
    "    print_matrix(camera_matrix)\n",
    "\n",
    "    # Open3D の点群の座標は Nx3 行列になっている\n",
    "    # 外部パラメータ行列をかけるため、転置し、さらに全てが1の行をを追加して4xN 行列にする\n",
    "    points = np.asarray(pcd.points).T\n",
    "    points = np.vstack([points, np.ones(points.shape[1])])\n",
    "    print(f\"Input points ({points.shape[0]}x{points.shape[1]}) (first 5 points)\") # noqa: T201 説明用にあえて print を使用\n",
    "    print_matrix(points[:, :(min(5, points.shape[1]))])\n",
    "\n",
    "\n",
    "    # ワールド座標系からカメラ座標系への変換\n",
    "    points_in_camera = extrinsic_matrix @ points\n",
    "    # カメラの前方にある点のみを残す\n",
    "    mask_in_front_of_camera = points_in_camera[2, :] > 0\n",
    "    points_in_camera = points_in_camera[:, mask_in_front_of_camera]\n",
    "\n",
    "    # カメラ座標系の点を正規化 (正規画像座標系への変換)\n",
    "    points_in_camera[:3] = points_in_camera[:3] / points_in_camera[2]\n",
    "\n",
    "    # カメラ座標系 (正規画像座標系) から画像座標系への変換\n",
    "    points_in_image = camera_matrix @ points_in_camera[:3]\n",
    "    # スクリーンの点群の座標は 0 <= x <= image_width, 0 <= y <= image_height であるため、範囲外の点を除去\n",
    "    points_in_image, mask_inside_image = filter_visible_points(points_in_image, image_size[0], image_size[1])\n",
    "\n",
    "\n",
    "    pcd_in_camera = o3d.geometry.PointCloud()\n",
    "    pcd_in_camera.points = o3d.utility.Vector3dVector(points_in_camera[:3].T)\n",
    "\n",
    "    projected_pcd = o3d.geometry.PointCloud()\n",
    "    projected_pcd.points = o3d.utility.Vector3dVector(points_in_image.T)\n",
    "\n",
    "    if return_with_color:\n",
    "        colors = np.asarray(pcd.colors)\n",
    "        colors = colors[mask_in_front_of_camera]\n",
    "        pcd_in_camera.colors = o3d.utility.Vector3dVector(colors)\n",
    "        projected_pcd.colors = o3d.utility.Vector3dVector(colors[mask_inside_image])\n",
    "\n",
    "    return projected_pcd, pcd_in_camera\n",
    "\n",
    "\n",
    "def projection_by_camera(\n",
    "        pcd: o3d.geometry.PointCloud,\n",
    "        camera: ICamera,\n",
    "        *,\n",
    "        return_with_color: bool = True) -> o3d.geometry.PointCloud:\n",
    "    \"\"\"\n",
    "    ICamera の world_to_camera メソッドを使用して点群を投影するバージョン.\n",
    "\n",
    "    Note:\n",
    "    ----\n",
    "    カメラモデルによってはカメラ座標から画像座標への変換が単純な行列の積で表せない場合がある。\n",
    "    ICamera ではワールド座標から画像座標への一般化された変換を world_to_camera で定義する。\n",
    "\n",
    "    \"\"\"\n",
    "    points = np.asarray(pcd.points).T\n",
    "    projected_points, mask_in_front_of_camera, mask_inside_image = camera.world_to_camera(points)\n",
    "\n",
    "    projected_pcd = o3d.geometry.PointCloud()\n",
    "    projected_pcd.points = o3d.utility.Vector3dVector(projected_points.T)\n",
    "    if return_with_color:\n",
    "        projected_pcd.colors = o3d.utility.Vector3dVector(\n",
    "            np.asarray(pcd.colors)[mask_in_front_of_camera][mask_inside_image])\n",
    "    return projected_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrinsic matrix (4x4)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}-1.000 & 0.000 & -0.000 & 2.500\\\\-0.000 & 0.000 & 1.000 & -2.500\\\\0.000 & 1.000 & -0.000 & 3.000\\\\0.000 & 0.000 & 0.000 & 1.000\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix (3x3)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}600.000 & 0.000 & 599.500\\\\0.000 & 600.000 & 449.500\\\\0.000 & 0.000 & 1.000\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input points (4x9261) (first 5 points)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.002 & -0.003 & -0.009 & 0.013 & -0.006\\\\0.017 & -0.006 & -0.005 & -0.006 & -0.015\\\\0.002 & 0.242 & 0.517 & 0.757 & 0.994\\\\1.000 & 1.000 & 1.000 & 1.000 & 1.000\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube_center = np.mean(np.asarray(cube.points), axis=0)\n",
    "\n",
    "camera_obj = base_camera_obj.copy()\n",
    "# cube の中心を見るようにカメラを移動、またカメラを少し後ろに引く\n",
    "camera_obj.translate([cube_center[0], -3, cube_center[2]])\n",
    "\n",
    "camera = base_camera.copy()\n",
    "camera.transform(camera_obj.get_transform())\n",
    "\n",
    "projected, normalized = projection_by_pinhole_camera(cube, camera, return_with_color=True)\n",
    "\n",
    "draw_geometries(normalized, world_coordinate, camera=view_camera,\n",
    "                title=\"正規画像座標系に変換された点群 (座標軸はカメラ座標系)\")\n",
    "draw_geometries(projected, image_coordinate, title=\"投影変換された点群 (座標軸は画像座標系)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ピンホールカメラによる投影変換 (別の例)\n",
    "\n",
    "今度は、カメラの位置を点群の角に移動し、カメラの向きを立方体の中心に向けてみましょう。\n",
    "\n",
    "カメラの位置を (x, y, z) = (-1, -1, -1) に移動し、さらに Euler 角 (45°, 45°, 0) (回転順序 x → y → z) で回転させます。\n",
    "\n",
    "下の左図はカメラと点群の位置関係を、右図は投影変換の結果を示しています。\n",
    "\n",
    "<img alt=\"Camera at a corner of the cube\" src=\"./notebook_assets/images/2_extra_camera_at_corner_of_cube.png\" style=\"width:600px;\" />\n",
    "<img alt=\"Projected cube\" src=\"./notebook_assets/images/2_extra_projected_cube_from_corner.png\" style=\"width:600px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_center = np.mean(np.asarray(cube.points), axis=0)\n",
    "\n",
    "camera_obj = base_camera_obj.copy()\n",
    "camera_obj.translate([-1, -1, -1])\n",
    "camera_obj.rotate_by_euler(EulerOrder.xyz, [45, 45, 0])\n",
    "\n",
    "camera = base_camera.copy()\n",
    "camera.transform(camera_obj.get_transform())\n",
    "\n",
    "draw_geometries(world_coordinate, cube, camera_obj, camera=camera, title=\"カメラセッティング\")\n",
    "\n",
    "projected = projection_by_camera(cube, camera)\n",
    "\n",
    "draw_geometries(\n",
    "    projected, o3d.geometry.TriangleMesh.create_coordinate_frame(size=500, origin=[0, 0, 0]), title=\"投影変換の結果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (参考) 魚眼レンズカメラのシミュレーション\n",
    "\n",
    "ここでは応用例として、魚眼レンズモデルによる投影変換を紹介します。\n",
    "\n",
    "魚眼カメラのモデルとして、[OCam Calib](https://sites.google.com/site/scarabotix/ocamcalib-omnidirectional-camera-calibration-toolbox-for-matlab) で定義されている Omnidirectional camera model を使用します。\n",
    "\n",
    "OCam Calib では、ワールド座標から正規画像座標への変換を、光軸からの距離を変数とする多項式で表現します。\n",
    "\n",
    "具体的な実装は [`util_lib/camera.py`](./util_lib/camera.py) の `OCamCalibFishEyeCamera`\n",
    "\n",
    "\n",
    "<img alt=\"Camera in the cube\" src=\"./notebook_assets/images/2_extra_camera_in_cube.png\" style=\"height:600px;\" />\n",
    "<img alt=\"Projected cube by the fish eye camera\" src=\"./notebook_assets/images/2_extra_projected_cube_from_inside_by_fish_eye.png\" style=\"height:600px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fish eye lense example: [Sunex DSL415](https://www.optics-online.com/OOL/DSL/DSL415.PDF)\n",
    "# Camera system example : [NavVis VLX2](https://www.navvis.com/vlx-2)\n",
    "\n",
    "fish_eye_param = OCamCalibOmniDirectionalCameraParameters(\n",
    "    world_to_cam_params=[\n",
    "        2175.0684380805101,\n",
    "        1363.2716547833479,\n",
    "        -221.43701011679701,\n",
    "        -328.90812452717728,\n",
    "        161.774047285835,\n",
    "        629.14819508054643,\n",
    "        -124.82718560288779,\n",
    "        -981.25167223042808,\n",
    "        -11.46872731590156,\n",
    "        1240.455151263159,\n",
    "        395.67008688719937,\n",
    "        -1010.9145248169081,\n",
    "        -668.30097100604326,\n",
    "        382.03149432595819,\n",
    "        479.82026899885392,\n",
    "        41.138604370760731,\n",
    "        -120.6327422172762,\n",
    "        -56.594318327261128,\n",
    "        -8.0040880097076297,\n",
    "    ],\n",
    "    affine_params_cde=(\n",
    "        1.000233130570753,\n",
    "        -0.00047428370003433208,\n",
    "        0.00057600897530624498,\n",
    "    ),\n",
    "    principal_point=(5000 / 2 - 0.5, 5000 / 2 - 0.5),\n",
    "    image_size=(5000, 5000),\n",
    "    fov=195,\n",
    ")\n",
    "\n",
    "base_fish_eye_camera = OCamCalibOmniDirectionalCamera(fish_eye_param, initial_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_center = np.mean(np.asarray(cube.points), axis=0)\n",
    "\n",
    "camera_obj = base_camera_obj.copy()\n",
    "# cube の中心を見るようにカメラを移動、またカメラを少し後ろに引く\n",
    "camera_obj.translate(cube_center * 0.75)\n",
    "camera_obj.rotate_by_euler(EulerOrder.xyz, [45, 45, 0])\n",
    "\n",
    "fish_eye_camera = base_fish_eye_camera.copy()\n",
    "fish_eye_camera.transform(camera_obj.get_transform())\n",
    "\n",
    "projected = projection_by_camera(cube, fish_eye_camera)\n",
    "\n",
    "draw_geometries(world_coordinate, cube, camera_obj, title=\"カメラセッティング\")\n",
    "draw_geometries(projected, o3d.geometry.TriangleMesh.create_coordinate_frame(size=2000, origin=[0, 0, 0]),\n",
    "                title=\"魚眼レンズカメラモデルでの投影変換の結果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下図はピンホールカメラによる投影変換の結果を示しています。\n",
    "\n",
    "魚眼レンズカメラのほうが広範囲が写り込んでおり、そのために元の空間の構造が変形して見えることがわかるでしょう。\n",
    "\n",
    "<img alt=\"Projected by pin-hole camera inside the cube\" src=\"./notebook_assets/images/2_extra_projected_cube_from_inside_by_pinhole.png\" style=\"width:600px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinhole_camera = base_camera.copy()\n",
    "pinhole_camera.transform(camera_obj.get_transform())\n",
    "\n",
    "projected_pinhole = projection_by_camera(cube, pinhole_camera)\n",
    "draw_geometries(projected_pinhole, image_coordinate, title=\"ピンホールカメラモデルでの投影変換の結果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
